# ğŸ“ AI Answer Evaluation System  
### Multimodal Human-Like Automated Grading using NLP & Whisper

---

## ğŸš€ Overview

The **AI Answer Evaluation System** is a multimodal intelligent grading platform that evaluates both **text and spoken student answers** using advanced Natural Language Processing techniques.

Unlike traditional keyword-based grading systems, this project uses:

- ğŸ§  Concept extraction
- ğŸ“Š Semantic similarity (Sentence-BERT)
- ğŸ™ï¸ Speech-to-text conversion (OpenAI Whisper)
- ğŸ“ Human-style feedback generation

This system mimics how a **real examiner evaluates answers**, providing meaningful scores and structured feedback.

---

## âœ¨ Key Features

### ğŸ“ Text-Based Answer Evaluation
- Extracts key concepts from model answers
- Measures semantic similarity
- Provides structured scoring
- Generates human-like feedback

### ğŸ§ Audio-Based Answer Evaluation
- Supports `.wav` and `.mp3` uploads
- Converts speech to text using Whisper
- Evaluates spoken responses using the same NLP pipeline
- Ensures multimodal grading capability

### ğŸ“Š Intelligent Scoring
- Concept coverage-based evaluation
- Depth detection (answer length analysis)
- Missing concept identification
- Structured feedback output

---

## ğŸ§  System Architecture

